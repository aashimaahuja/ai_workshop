## OpenAI API with Python

This document demonstrates how to use the OpenAI API with Python to perform text summarization. We'll walk through the steps of importing the necessary libraries, loading your API key, initializing the client, and making a call to the Chat API.

### Step 1: Import Libraries and Load API Key

First, import the required libraries and load your OpenAI API key from an environment variable.

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
```

### Step 2: Initialize the OpenAI Client

Next, initialize the OpenAI client using your API key.

```python
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
```

### Step 3: Call the Chat API for Text Summarization

Now, let's call the Chat API to summarize a given text. We'll use the new syntax for the Chat API.

```python
input_text = """
Large language models (LLMs) are a type of artificial intelligence that can generate human-like text based on the input they receive. These models are trained on massive datasets and can perform a wide range of language tasks, such as translation, summarization, and question answering. However, they also come with challenges like hallucination, bias, and the need for large amounts of computational power.
"""

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant that summarizes text."},
        {"role": "user", "content": f"Summarize this:\n\n{input_text}"}
    ],
    temperature=0.5
)

print(response.choices[0].message.content)
```

---

### Understanding Roles in Chat Completions API

When using the Chat Completions API (like OpenAI’s GPT models), every message in a conversation has a **role**. These roles help the model understand who is saying what and how it should respond.

There are **three main roles**:

### 1. `system`

- Sets the **tone or instructions** for the assistant.
- Think of it as the **director** telling the assistant how to act.
- It is the **first message** in the conversation.

**Example:**

```json
{ "role": "system", "content": "You are a friendly assistant who explains concepts simply." }
```

### 1. `user`
- Represents the person using the app or asking questions.

- This is the input from the end user.

```json
{ "role": "user", "content": "What is a closure in JavaScript?" }
```

### 3. `assistant`
- Represents the model’s response.
- The answer or reply generated by the assistant..

```json
{ "role": "assistant", "content": "A closure is a function that retains access to its scope..." }
```

---

## Structured Output with OpenAI API

The OpenAI API can be used to generate structured outputs like bullet points or JSON format. This is particularly useful when you need to process the response programmatically or present information in a specific format.

### Bullet Point Summary

To get a bullet-point summary, you can modify the system prompt and user request:

```python
response_bullets = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant that summarizes text into bullet points."},
        {"role": "user", "content": f"Summarize the following text into 3-5 concise bullet points:\n\n{input_text}"}
    ],
    temperature=0.4
)

print(response_bullets.choices[0].message.content)
```

### JSON Format Output

For JSON output, you can specify the desired structure in your prompt:

```python
response_json = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant that returns summaries in JSON format."},
        {"role": "user", "content":  f"Summarize the following text and return the result as a JSON object with a 'summary' field and a 'key_points' array of strings:\n\n{input_text}"}
    ],
    temperature=0.4
)

print(response_bullets.choices[0].message.content)
```

### Custom Structure

You can also define your own custom structure based on your needs:

```python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant that extracts structured information from text."},
        {"role": "user", "content": f"""Extract information in the following format:
        {{
            "topics": [],
            "entities": [],
            "sentiment": "",
            "action_items": []
        }}
        Text to analyze:
        {input_text}"""}
    ],
    temperature=0.5
)

# Parse and use the structured output
structured_data = response.choices[0].message.content

```
